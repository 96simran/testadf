name: Deploy ADF to QA via selection

on:
  push:
    branches:
      - adf_publish

jobs:
  deploy:
    runs-on: ubuntu-latest

    # env:
    #   AZURE_CREDENTIALS: ${{ secrets.AZURE_CREDENTIALS }}
    #   RESOURCE_GROUP: Test-adf
    #   SOURCE_ADF: QA-testing-adf
    #   PIPELINE_NAME: MoveFiles

    steps:
    # - name: Checkout code
    #   uses: actions/checkout@v3

    - name: Download and deploy ADF pipeline
      env:
        TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
        CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
        CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
        SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
        TARGET_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
        TARGET_RESOURCE_GROUP: Test-adf
        TARGET_FACTORY_NAME: QA-testing-adf
        TARGET_PIPELINE_NAME: MoveFiles1
      run: |
        # Get token
        ACCESS_TOKEN=$(curl -X POST -H "Content-Type: application/x-www-form-urlencoded" \
          -d "grant_type=client_credentials&client_id=$CLIENT_ID&client_secret=$CLIENT_SECRET&resource=https://management.azure.com/" \
          "https://login.microsoftonline.com/$TENANT_ID/oauth2/token" | jq -r .access_token)

        # Export selected pipeline from ADF using REST API and access token
        RESOURCE_GROUP="Test-adf"
        FACTORY_NAME="testing-adf-repo"
        PIPELINE_NAME="MoveFiles"

        curl -X GET "https://management.azure.com/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP/providers/Microsoft.DataFactory/factories/$FACTORY_NAME/pipelines/$PIPELINE_NAME?api-version=2018-06-01" \
          -H "Authorization: Bearer $ACCESS_TOKEN" \
          -H "Content-Type: application/json" \
          -o pipeline.json
          echo pipeline.json

        # Export linked service
        jq -r '..|.linkedServiceName? // empty' pipeline.json | sort -u

        # Export dataset
        jq -r '[..|.inputs? // empty, ..|.outputs? // empty] | flatten | .[]?.referenceName // empty' pipeline.json | sort -u

        # Extract linked services
        LINKED_SERVICES=$(jq -r '..|.linkedServiceName? // empty' pipeline.json | sort -u)
        for LS in $LINKED_SERVICES; do
          echo "Exporting linked service: $LS"
          curl -X GET "https://management.azure.com/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP/providers/Microsoft.DataFactory/factories/$FACTORY_NAME/linkedservices/$LS?api-version=2018-06-01" \
            -H "Authorization: Bearer $ACCESS_TOKEN" \
            -H "Content-Type: application/json" \
            -o "linkedservice_${LS}.json"
        done

        # Extract datasets
        DATASETS=$(jq -r '[..|.inputs? // empty, ..|.outputs? // empty] | flatten | .[]?.referenceName // empty' pipeline.json | sort -u)
        for DS in $DATASETS; do
          echo "Exporting dataset: $DS"
          curl -X GET "https://management.azure.com/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP/providers/Microsoft.DataFactory/factories/$FACTORY_NAME/datasets/$DS?api-version=2018-06-01" \
            -H "Authorization: Bearer $ACCESS_TOKEN" \
            -H "Content-Type: application/json" \
            -o "dataset_${DS}.json"
        done

        # Import and publish updated pipeline to QA environment ADF
        curl -X PUT "https://management.azure.com/subscriptions/$TARGET_SUBSCRIPTION_ID/resourceGroups/$TARGET_RESOURCE_GROUP/providers/Microsoft.DataFactory/factories/$TARGET_FACTORY_NAME/pipelines/$TARGET_PIPELINE_NAME?api-version=2018-06-01" \
          -H "Authorization: Bearer $ACCESS_TOKEN" \
          -H "Content-Type: application/json" \
          --data @pipeline.json

    - name: upload artifacts
      uses: actions/upload-artifact@v4
      with:
        name: adf_artifacts
        path: |
          pipeline.json
          linkedservice_*.json
          dataset_*.json  
        

          # Update input source linked services
          OLD_LINKED_SERVICE_INPUT="devlinkinputsource"
          NEW_LINKED_SERVICE_INPUT="qalinkputsource"

          for DS_JSON in dataset_*.json
          do
            echo "Checking for input source linked service in $DS_JSON"
            tmpfile=$(mktemp)
            jq --arg OLD "$OLD_LINKED_SERVICE_INPUT" --arg NEW "$NEW_LINKED_SERVICE_INPUT" \
              'if .properties.linkedServiceName.referenceName == $OLD 
                then .properties.linkedServiceName.referenceName = $NEW 
                else . end' \
              "$DS_JSON" > "$tmpfile" && mv "$tmpfile" "$DS_JSON"
          done

          # Update output (sink) linked services
          OLD_LINKED_SERVICE_OUTPUT="devlinkoutputsource"
          NEW_LINKED_SERVICE_OUTPUT="qalinkoutputsource"

          for DS_JSON in dataset_*.json
          do
            echo "Checking for output source linked service in $DS_JSON"
            tmpfile=$(mktemp)
            jq --arg OLD "$OLD_LINKED_SERVICE_OUTPUT" --arg NEW "$NEW_LINKED_SERVICE_OUTPUT" \
              'if .properties.linkedServiceName.referenceName == $OLD 
                then .properties.linkedServiceName.referenceName = $NEW 
                else . end' \
              "$DS_JSON" > "$tmpfile" && mv "$tmpfile" "$DS_JSON"
          done