name: Promote ADF Pipeline to QA using QA_ linked services (mapping datasets)

on:
  push:
    branches:
      - adf_publish

env:
  TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
  CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
  CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
  SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
  RESOURCE_GROUP: Test-adf
  DEV_FACTORY_NAME: testing-adf-repo
  TARGET_RESOURCE_GROUP: Test-adf
  TARGET_FACTORY_NAME: QA-testing-adf
  TARGET_PIPELINE_NAME: Delete_files
  API_VERSION: 2018-06-01
  QA_LINKED_SERVICE_NAME: QA_AzureBlobStorage_migrate

jobs:
  promote:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq curl

      - name: Get Azure Access Token
        id: get_token
        run: |
          ACCESS_TOKEN=$(curl -s -X POST -H "Content-Type: application/x-www-form-urlencoded" \
            -d "grant_type=client_credentials&client_id=$CLIENT_ID&client_secret=$CLIENT_SECRET&resource=https://management.azure.com/" \
            "https://login.microsoftonline.com/$TENANT_ID/oauth2/token" | jq -r .access_token)
          echo "::add-mask::$ACCESS_TOKEN"
          echo "access_token=$ACCESS_TOKEN" >> $GITHUB_OUTPUT

      - name: Export pipeline from Dev
        env:
          ACCESS_TOKEN: ${{ steps.get_token.outputs.access_token }}
        run: |
          curl -s -X GET "https://management.azure.com/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP/providers/Microsoft.DataFactory/factories/$DEV_FACTORY_NAME/pipelines/$TARGET_PIPELINE_NAME?api-version=$API_VERSION" \
            -H "Authorization: Bearer $ACCESS_TOKEN" \
            -H "Content-Type: application/json" \
            -o pipeline.json
          cat pipeline.json
          if grep -q '"error"' pipeline.json; then
            echo "Failed to export pipeline! Contents of pipeline.json:"
            cat pipeline.json
            exit 1
          fi

      - name: Get all datasets in DEV and QA environment
        env:
          ACCESS_TOKEN: ${{ steps.get_token.outputs.access_token }}
          RESOURCE_GROUP: ${{ env.RESOURCE_GROUP }}
          DEV_FACTORY_NAME: ${{ env.DEV_FACTORY_NAME }}
          TARGET_RESOURCE_GROUP: ${{ env.TARGET_RESOURCE_GROUP }}
          TARGET_FACTORY_NAME: ${{ env.TARGET_FACTORY_NAME }}
          SUBSCRIPTION_ID: ${{ env.SUBSCRIPTION_ID }}
          API_VERSION: ${{ env.API_VERSION }}
        run: |
          # Get DEV
          curl -s -X GET "https://management.azure.com/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP/providers/Microsoft.DataFactory/factories/$DEV_FACTORY_NAME/datasets?api-version=$API_VERSION" \
            -H "Authorization: Bearer $ACCESS_TOKEN" | jq -r '.value[].name' | sort -u > dev_datasets.txt
          echo "DEV datasets:"; cat dev_datasets.txt
          # Get QA
          curl -s -X GET "https://management.azure.com/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$TARGET_RESOURCE_GROUP/providers/Microsoft.DataFactory/factories/$TARGET_FACTORY_NAME/datasets?api-version=$API_VERSION" \
            -H "Authorization: Bearer $ACCESS_TOKEN" | jq -r '.value[].name' | sort -u > qa_datasets.txt
          echo "QA datasets:"; cat qa_datasets.txt

      - name: Build dataset mapping (Dev to QA)
        run: |
          # Assumed naming: Dev_XYZ -> QA_XYZ or dev_xyz -> QA_xyz, case-insensitive
          > dataset_map.txt
          while read dev; do
            # Try to find a QA dataset that matches after replacing Dev_ with QA_ (case-insensitive)
            qa_match=$(grep -i "^QA_$(echo "${dev#Dev_}" | sed 's/^dev_//I')" qa_datasets.txt | head -n1)
            if [ -n "$qa_match" ]; then
              echo "$dev,$qa_match" >> dataset_map.txt
            fi
          done < dev_datasets.txt
          echo "Dataset mapping (Dev to QA):"
          cat dataset_map.txt

      - name: Replace linked service and dataset references in pipeline with mapped QA names
        env:
          QA_LINKED_SERVICE_NAME: ${{ env.QA_LINKED_SERVICE_NAME }}
        run: |
          # Build jq code for dataset replacements
          jq_script='walk(
            if type == "object" and has("referenceName") and has("type") then
              if .type == "LinkedServiceReference" then
                .referenceName = env.QA_LINKED_SERVICE_NAME
              elif .type == "DatasetReference" then
                # Placeholder for mapping logic
                .referenceName = .referenceName
              else
                .
              end
            else .
            end
          )'
          jq "$jq_script" pipeline.json > pipeline_mapped.json

          # Now, replace dataset referenceNames per mapping
          cp pipeline_mapped.json pipeline_qa_final.json
          while IFS=, read -r dev qa; do
            # Replace all references matching the DEV dataset with the mapped QA dataset
            tmpfile=$(mktemp)
            jq --arg dev "$dev" --arg qa "$qa" '
              walk(
                if type == "object" and has("referenceName") and has("type") and .type == "DatasetReference" and .referenceName == $dev then
                  .referenceName = $qa
                else .
                end
              )
            ' pipeline_qa_final.json > "$tmpfile" && mv "$tmpfile" pipeline_qa_final.json
          done < dataset_map.txt

          cat pipeline_qa_final.json

      - name: Deploy pipeline to QA Data Factory
        env:
          ACCESS_TOKEN: ${{ steps.get_token.outputs.access_token }}
          TARGET_RESOURCE_GROUP: ${{ env.TARGET_RESOURCE_GROUP }}
          TARGET_FACTORY_NAME: ${{ env.TARGET_FACTORY_NAME }}
          SUBSCRIPTION_ID: ${{ env.SUBSCRIPTION_ID }}
          API_VERSION: ${{ env.API_VERSION }}
          TARGET_PIPELINE_NAME: ${{ env.TARGET_PIPELINE_NAME }}
        run: |
          curl -s -X PUT "https://management.azure.com/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$TARGET_RESOURCE_GROUP/providers/Microsoft.DataFactory/factories/$TARGET_FACTORY_NAME/pipelines/$TARGET_PIPELINE_NAME?api-version=$API_VERSION" \
            -H "Authorization: Bearer $ACCESS_TOKEN" \
            -H "Content-Type: application/json" \
            --data @pipeline_qa_final.json | tee deploy_output.json
          if grep -q '"error"' deploy_output.json; then
            echo "Failed to deploy pipeline"
            cat deploy_output.json
            exit 1
          fi

      - name: Upload all artifacts
        uses: actions/upload-artifact@v4
        with:
          name: adf_artifacts
          path: |
            pipeline.json
            pipeline_mapped.json
            pipeline_qa_final.json
            dev_datasets.txt
            qa_datasets.txt
            dataset_map.txt
            