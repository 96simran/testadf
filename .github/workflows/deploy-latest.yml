name: Promote ADF Pipeline to QA using QA_ prefixed datasets

on:
  push:
    branches:
      - adf_publish

env:
  TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
  CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
  CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
  SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
  RESOURCE_GROUP: Test-adf
  DEV_FACTORY_NAME: testing-adf-repo
  TARGET_RESOURCE_GROUP: Test-adf
  TARGET_FACTORY_NAME: QA-testing-adf
  TARGET_PIPELINE_NAME: MoveFiles1
  API_VERSION: 2018-06-01

jobs:
  promote:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq curl

      - name: Get Azure Access Token
        id: get_token
        run: |
          ACCESS_TOKEN=$(curl -s -X POST -H "Content-Type: application/x-www-form-urlencoded" \
            -d "grant_type=client_credentials&client_id=$CLIENT_ID&client_secret=$CLIENT_SECRET&resource=https://management.azure.com/" \
            "https://login.microsoftonline.com/$TENANT_ID/oauth2/token" | jq -r .access_token)
          echo "::add-mask::$ACCESS_TOKEN"
          echo "access_token=$ACCESS_TOKEN" >> $GITHUB_OUTPUT

      - name: Export pipeline from Dev
        env:
          ACCESS_TOKEN: ${{ steps.get_token.outputs.access_token }}
        run: |
          curl -s -X GET "https://management.azure.com/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP/providers/Microsoft.DataFactory/factories/$DEV_FACTORY_NAME/pipelines/$TARGET_PIPELINE_NAME?api-version=$API_VERSION" \
            -H "Authorization: Bearer $ACCESS_TOKEN" \
            -H "Content-Type: application/json" \
            -o pipeline.json
          cat pipeline.json
          if grep -q '"error"' pipeline.json; then
            echo "Failed to export pipeline! Contents of pipeline.json:"
            cat pipeline.json
            exit 1
          fi

      - name: Prefix all referenceNames in JSON for QA (use QA_ datasets)
        run: |
          jq 'walk(
              if type == "object" and has("referenceName") and (.referenceName | startswith("QA_") | not) then
                .referenceName |= "QA_" + .
              else .
              end
            )' pipeline.json > pipeline_qa.json
          cat pipeline_qa.json
          if grep -q '"error"' pipeline_qa.json; then
            echo "Pipeline QA JSON is not valid! Contents:"
            cat pipeline_qa.json
            exit 1
          fi

      - name: Extract required QA dataset names
        run: |
          jq -r '.. | objects | select(has("referenceName")) | .referenceName' pipeline_qa.json | sort -u > required_qa_datasets.txt
          echo "Required QA datasets:"
          cat required_qa_datasets.txt

      - name: Get existing dataset names in QA env
        env:
          ACCESS_TOKEN: ${{ steps.get_token.outputs.access_token }}
          TARGET_RESOURCE_GROUP: ${{ env.TARGET_RESOURCE_GROUP }}
          TARGET_FACTORY_NAME: ${{ env.TARGET_FACTORY_NAME }}
          SUBSCRIPTION_ID: ${{ env.SUBSCRIPTION_ID }}
          API_VERSION: ${{ env.API_VERSION }}
        run: |
          curl -s -X GET "https://management.azure.com/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$TARGET_RESOURCE_GROUP/providers/Microsoft.DataFactory/factories/$TARGET_FACTORY_NAME/datasets?api-version=$API_VERSION" \
            -H "Authorization: Bearer $ACCESS_TOKEN" \
            -H "Content-Type: application/json" \
            -o qa_datasets_list.json
          jq -r '.value[].name' qa_datasets_list.json | sort -u > existing_qa_datasets.txt
          echo "Existing QA datasets:"
          cat existing_qa_datasets.txt

      - name: Fail if any required QA datasets are missing
        run: |
          missing=$(comm -23 required_qa_datasets.txt existing_qa_datasets.txt || true)
          if [ -n "$missing" ]; then
            echo "The following required QA datasets are missing in the QA environment:"
            echo "$missing"
            exit 1
          else
            echo "All required QA datasets are present in the QA environment."
          fi

      - name: Deploy QA pipeline to QA Data Factory
        env:
          ACCESS_TOKEN: ${{ steps.get_token.outputs.access_token }}
          TARGET_RESOURCE_GROUP: ${{ env.TARGET_RESOURCE_GROUP }}
          TARGET_FACTORY_NAME: ${{ env.TARGET_FACTORY_NAME }}
          SUBSCRIPTION_ID: ${{ env.SUBSCRIPTION_ID }}
          API_VERSION: ${{ env.API_VERSION }}
          TARGET_PIPELINE_NAME: ${{ env.TARGET_PIPELINE_NAME }}
        run: |
          curl -s -X PUT "https://management.azure.com/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$TARGET_RESOURCE_GROUP/providers/Microsoft.DataFactory/factories/$TARGET_FACTORY_NAME/pipelines/$TARGET_PIPELINE_NAME?api-version=$API_VERSION" \
            -H "Authorization: Bearer $ACCESS_TOKEN" \
            -H "Content-Type: application/json" \
            --data @pipeline_qa.json | tee deploy_output.json
          if grep -q '"error"' deploy_output.json; then
            echo "Failed to deploy pipeline"
            cat deploy_output.json
            exit 1
          fi

      - name: Upload all artifacts
        uses: actions/upload-artifact@v4
        with:
          name: adf_artifacts
          path: |
            pipeline.json
            pipeline_qa.json
            required_qa_datasets.txt
            existing_qa_datasets.txt
            