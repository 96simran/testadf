name: Promote ADF Pipeline to QA with Input Validation

on:
  workflow_dispatch:
    inputs:
      qalinkserviceinput:
        description: 'Name of the linked service to check in QA'
        required: true
        default: 'AzureBlobStorage'
      qalinkserviceoutput:
        description: 'Name of the output linked service to check in QA'
        required: true
        default: 'AzureSqlDatabase'
      qadatasetinput:
        description: 'Name of the input dataset to check in QA'
        required: true
        default: 'binarydatasource_folder1'
      qadatasetoutput:
        description: 'Name of the output dataset to check in QA'
        required: true
        default: 'azuresqldatasetfolder1'

env:
  TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
  CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
  CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
  SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
  RESOURCE_GROUP: Test-adf
  DEV_FACTORY_NAME: testing-adf-repo
  TARGET_RESOURCE_GROUP: Test-adf
  TARGET_FACTORY_NAME: QA-testing-adf
  TARGET_PIPELINE_NAME: MoveFiles1
  API_VERSION: 2018-06-01

jobs:
  promote:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq curl

      - name: Get Azure Access Token
        id: get_token
        run: |
          ACCESS_TOKEN=$(curl -s -X POST -H "Content-Type: application/x-www-form-urlencoded" \
            -d "grant_type=client_credentials&client_id=$CLIENT_ID&client_secret=$CLIENT_SECRET&resource=https://management.azure.com/" \
            "https://login.microsoftonline.com/$TENANT_ID/oauth2/token" | jq -r .access_token)
          echo "::add-mask::$ACCESS_TOKEN"
          echo "access_token=$ACCESS_TOKEN" >> $GITHUB_OUTPUT

      - name: Export pipeline from Dev
        env:
          ACCESS_TOKEN: ${{ steps.get_token.outputs.access_token }}
        run: |
          curl -s -X GET "https://management.azure.com/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP/providers/Microsoft.DataFactory/factories/$DEV_FACTORY_NAME/pipelines/$TARGET_PIPELINE_NAME?api-version=$API_VERSION" \
            -H "Authorization: Bearer $ACCESS_TOKEN" \
            -H "Content-Type: application/json" \
            -o pipeline.json
          cat pipeline.json
          if grep -q '"error"' pipeline.json; then
            echo "Failed to export pipeline! Contents of pipeline.json:"
            cat pipeline.json
            exit 1
          fi

      - name: Prepare lists of required linked services and datasets from input
        run: |
          echo "${{ github.event.inputs.qalinkserviceinput }}" > required_linked_services.txt
          echo "${{ github.event.inputs.qalinkserviceoutput }}" >> required_linked_services.txt
          sort -u required_linked_services.txt -o required_linked_services.txt

          echo "${{ github.event.inputs.qadatasetinput }}" > required_datasets.txt
          echo "${{ github.event.inputs.qadatasetoutput }}" >> required_datasets.txt
          sort -u required_datasets.txt -o required_datasets.txt

      - name: Check for required linked services in QA
        env:
          ACCESS_TOKEN: ${{ steps.get_token.outputs.access_token }}
        run: |
          curl -s -X GET "https://management.azure.com/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$TARGET_RESOURCE_GROUP/providers/Microsoft.DataFactory/factories/$TARGET_FACTORY_NAME/linkedservices?api-version=$API_VERSION" \
            -H "Authorization: Bearer $ACCESS_TOKEN" \
            -H "Content-Type: application/json" \
            -o qa_linked_services_list.json
          jq -r '.value[].name' qa_linked_services_list.json | sort -u > existing_qa_linked_services.txt
          echo "Existing QA linked services:"
          cat existing_qa_linked_services.txt

          missing=$(comm -23 required_linked_services.txt existing_qa_linked_services.txt || true)
          if [ -n "$missing" ]; then
            echo "The following linked services are missing in the QA environment:"
            echo "$missing"
            exit 1
          else
            echo "All input linked services are present in the QA environment."
          fi

      - name: Check for required datasets in QA
        env:
          ACCESS_TOKEN: ${{ steps.get_token.outputs.access_token }}
        run: |
          curl -s -X GET "https://management.azure.com/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$TARGET_RESOURCE_GROUP/providers/Microsoft.DataFactory/factories/$TARGET_FACTORY_NAME/datasets?api-version=$API_VERSION" \
            -H "Authorization: Bearer $ACCESS_TOKEN" \
            -H "Content-Type: application/json" \
            -o qa_datasets_list.json
          jq -r '.value[].name' qa_datasets_list.json | sort -u > existing_qa_datasets.txt
          echo "Existing QA datasets:"
          cat existing_qa_datasets.txt

          missing=$(comm -23 required_datasets.txt existing_qa_datasets.txt || true)
          if [ -n "$missing" ]; then
            echo "The following datasets are missing in the QA environment:"
            echo "$missing"
            exit 1
          else
            echo "All input datasets are present in the QA environment."
          fi

      - name: Deploy pipeline to QA Data Factory
        env:
          ACCESS_TOKEN: ${{ steps.get_token.outputs.access_token }}
        run: |
          curl -s -X PUT "https://management.azure.com/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$TARGET_RESOURCE_GROUP/providers/Microsoft.DataFactory/factories/$TARGET_FACTORY_NAME/pipelines/$TARGET_PIPELINE_NAME?api-version=$API_VERSION" \
            -H "Authorization: Bearer $ACCESS_TOKEN" \
            -H "Content-Type: application/json" \
            --data @pipeline.json | tee deploy_output.json
          if grep -q '"error"' deploy_output.json; then
            echo "Failed to deploy pipeline"
            cat deploy_output.json
            exit 1
          fi

      - name: Upload all artifacts
        uses: actions/upload-artifact@v4
        with:
          name: adf_artifacts
          path: |
            pipeline.json
            required_linked_services.txt
            required_datasets.txt
            existing_qa_linked_services.txt
            existing_qa_datasets.txt